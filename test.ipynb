{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching video: Exception while accessing title of https://youtube.com/watch?v=X7Zd4VyUgL0. Please file a bug report at https://github.com/pytube/pytube\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "try:\n",
    "    yt = YouTube(\"https://www.youtube.com/watch?v=X7Zd4VyUgL0\")\n",
    "    print(f\"Video Title: {yt.title}\")\n",
    "    print(f\"Video Length: {yt.length} seconds\")\n",
    "except Exception as e:\n",
    "    print(\"Error fetching video:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI vs ML vs DL vs Generative Ai\n",
      "Duration: 960 seconds\n",
      "Error loading transcript: Exception while accessing title of https://youtube.com/watch?v=X7Zd4VyUgL0. Please file a bug report at https://github.com/pytube/pytube\n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "def get_video_info(video_url):\n",
    "    \"\"\"Fetch YouTube video information using yt-dlp.\"\"\"\n",
    "    ydl_opts = {\"quiet\": True, \"format\": \"bestaudio/best\"}\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "            title = info.get(\"title\", \"Unknown Title\")\n",
    "            duration = info.get(\"duration\", \"Unknown Duration\")\n",
    "            description = info.get(\"description\", \"\")\n",
    "            print(f\"Title: {title}\\nDuration: {duration} seconds\")\n",
    "            return {\"title\": title, \"duration\": duration, \"description\": description}\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching video info: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Video URL\n",
    "generic_url = \"https://www.youtube.com/watch?v=X7Zd4VyUgL0\"\n",
    "\n",
    "# Fetch and print video metadata\n",
    "video_info = get_video_info(generic_url)\n",
    "\n",
    "# Use LangChain YoutubeLoader to extract transcript\n",
    "try:\n",
    "    loader = YoutubeLoader.from_youtube_url(generic_url, add_video_info=True)\n",
    "    docs = loader.load()\n",
    "    print(\"Documents:\", docs)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading transcript: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI vs ML vs DL vs Generative Ai, Duration: 960 seconds\n",
      "Transcript: [{'text': 'hello all my name is Kush naak and', 'start': 0.52, 'duration': 4.04}, {'text': 'welcome to my YouTube channel so guys', 'start': 2.44, 'duration': 3.76}, {'text': 'three to four years back you know I had', 'start': 4.56, 'duration': 4.52}, {'text': 'created a video uh to make you', 'start': 6.2, 'duration': 4.359}, {'text': 'understand the differences between AI', 'start': 9.08, 'duration': 4.479}, {'text': 'versus ml versus DL versus data science', 'start': 10.559, 'duration': 5.24}, {'text': 'and uh till now probably that is the', 'start': 13.559, 'duration': 4.201}, {'text': 'video and that was a 9 Minutes video', 'start': 15.799, 'duration': 5.081}, {'text': 'where I clearly differentiated between', 'start': 17.76, 'duration': 5.48}, {'text': 'all these terms right specifically that', 'start': 20.88, 'duration': 4.6}, {'text': 'you see over here and right now that is', 'start': 23.24, 'duration': 4.6}, {'text': 'probably the most highest views video in', 'start': 25.48, 'duration': 6.24}, {'text': 'my channel uh now as you know from past', 'start': 27.84, 'duration': 7.68}, {'text': 'two years like from 2022 end until now', 'start': 31.72, 'duration': 7.32}, {'text': 'right generative AI is really the Talk', 'start': 35.52, 'duration': 5.84}, {'text': 'of the Town you know and uh with respect', 'start': 39.04, 'duration': 3.96}, {'text': 'to generative AI if I talk about large', 'start': 41.36, 'duration': 3.08}, {'text': 'language models open source large', 'start': 43.0, 'duration': 4.32}, {'text': 'language models open AI doing s such an', 'start': 44.44, 'duration': 5.4}, {'text': 'amazing word now cloudy 3 is also there', 'start': 47.32, 'duration': 4.6}, {'text': 'to compete open aai you know and Amazon', 'start': 49.84, 'duration': 3.92}, {'text': 'is definitely supporting them so you', 'start': 51.92, 'duration': 4.119}, {'text': 'should know right what exactly is', 'start': 53.76, 'duration': 4.759}, {'text': 'generative AI how is it different from', 'start': 56.039, 'duration': 4.561}, {'text': 'all these terms or what is ex difference', 'start': 58.519, 'duration': 4.761}, {'text': 'between AI versus ml versus DL versus', 'start': 60.6, 'duration': 5.559}, {'text': \"generative AI so I'll make you\", 'start': 63.28, 'duration': 4.32}, {'text': 'understand in this specific video', 'start': 66.159, 'duration': 3.241}, {'text': \"probably I'll try to make this video\", 'start': 67.6, 'duration': 4.6}, {'text': 'from somewhere between 15 to 20 minutes', 'start': 69.4, 'duration': 5.399}, {'text': \"um I'll be including all simplistic\", 'start': 72.2, 'duration': 4.72}, {'text': 'terms very easy definition so that', 'start': 74.799, 'duration': 4.201}, {'text': \"you'll be able to understand it because\", 'start': 76.92, 'duration': 5.159}, {'text': 'once you have that Clarity right uh at', 'start': 79.0, 'duration': 4.96}, {'text': 'the end of the day right you really want', 'start': 82.079, 'duration': 4.04}, {'text': 'to probably become an AI engineer you', 'start': 83.96, 'duration': 4.08}, {'text': 'know which uses all these Technologies', 'start': 86.119, 'duration': 5.281}, {'text': \"to create that AI apps so uh let's go\", 'start': 88.04, 'duration': 5.92}, {'text': \"ahead and let's understand this thing\", 'start': 91.4, 'duration': 5.2}, {'text': 'okay so as usual when I probably start', 'start': 93.96, 'duration': 5.119}, {'text': 'the session you know let us consider the', 'start': 96.6, 'duration': 5.92}, {'text': 'entire universe and uh in this field of', 'start': 99.079, 'duration': 6.121}, {'text': 'universe I would definitely like to call', 'start': 102.52, 'duration': 6.68}, {'text': 'this as AI okay now what is', 'start': 105.2, 'duration': 6.8}, {'text': 'AI simple artificial intelligence the', 'start': 109.2, 'duration': 4.8}, {'text': 'main aim is to', 'start': 112.0, 'duration': 4.96}, {'text': 'build', 'start': 114.0, 'duration': 4.84}, {'text': 'applications that', 'start': 116.96, 'duration': 4.56}, {'text': 'can', 'start': 118.84, 'duration': 5.639}, {'text': 'perform that can', 'start': 121.52, 'duration': 6.959}, {'text': 'perform its own', 'start': 124.479, 'duration': 6.881}, {'text': 'task', 'start': 128.479, 'duration': 5.961}, {'text': 'without human intervention now this is', 'start': 131.36, 'duration': 7.959}, {'text': 'the most important definition right', 'start': 134.44, 'duration': 7.56}, {'text': \"without human intervention so it'll be\", 'start': 139.319, 'duration': 5.961}, {'text': 'able to perform its entire task without', 'start': 142.0, 'duration': 5.92}, {'text': 'human intervention so let me just talk', 'start': 145.28, 'duration': 5.0}, {'text': 'about it some of the examples As We Know', 'start': 147.92, 'duration': 5.84}, {'text': 'uh Netflix right it has a amazing AI', 'start': 150.28, 'duration': 6.039}, {'text': 'recommendation system recommendation', 'start': 153.76, 'duration': 5.8}, {'text': 'system which recommends movies right now', 'start': 156.319, 'duration': 5.601}, {'text': 'here human intervention is not required', 'start': 159.56, 'duration': 4.0}, {'text': 'to probably provide you some kind of', 'start': 161.92, 'duration': 4.039}, {'text': 'recommendation whatever things you using', 'start': 163.56, 'duration': 3.88}, {'text': \"you're browsing the movies whatever\", 'start': 165.959, 'duration': 3.681}, {'text': 'movies you are specifically seeing you', 'start': 167.44, 'duration': 4.48}, {'text': 'know at that point of time this AI model', 'start': 169.64, 'duration': 4.599}, {'text': 'is actually helping you to provide you', 'start': 171.92, 'duration': 3.679}, {'text': 'good recommendations so that you can', 'start': 174.239, 'duration': 3.521}, {'text': 'stay for a longer period of time', 'start': 175.599, 'duration': 4.28}, {'text': 'self-driving car is another example okay', 'start': 177.76, 'duration': 5.479}, {'text': 'okay so self-driving car is another', 'start': 179.879, 'duration': 6.241}, {'text': 'example right self-driving car now it is', 'start': 183.239, 'duration': 4.72}, {'text': 'able to probably drive itself you know', 'start': 186.12, 'duration': 3.199}, {'text': 'whenever the Turning is coming', 'start': 187.959, 'duration': 3.601}, {'text': 'everything it is able to do see at the', 'start': 189.319, 'duration': 4.0}, {'text': 'end of the day whichever field you', 'start': 191.56, 'duration': 4.48}, {'text': 'specifically work right uh if I talk', 'start': 193.319, 'duration': 4.961}, {'text': 'about AI Engineers this is very much', 'start': 196.04, 'duration': 4.44}, {'text': 'important if I talk about AI engineers', 'start': 198.28, 'duration': 3.76}, {'text': 'at the end of the', 'start': 200.48, 'duration': 4.64}, {'text': 'day at the end of the day you are', 'start': 202.04, 'duration': 6.04}, {'text': 'actually creating an AI product right', 'start': 205.12, 'duration': 5.64}, {'text': 'and this product may be integrated with', 'start': 208.08, 'duration': 4.359}, {'text': 'the software product itself right if I', 'start': 210.76, 'duration': 4.08}, {'text': 'say Netflix it is a streaming platform', 'start': 212.439, 'duration': 4.88}, {'text': 'movie streaming platform and if I talk', 'start': 214.84, 'duration': 4.16}, {'text': 'about AI Engineers you know they are', 'start': 217.319, 'duration': 4.681}, {'text': 'trying to integrate some amazing models', 'start': 219.0, 'duration': 5.28}, {'text': 'you know which involves fine tuning', 'start': 222.0, 'duration': 3.799}, {'text': 'which involves multiple things so that', 'start': 224.28, 'duration': 3.159}, {'text': 'you integrate in such a way that it is', 'start': 225.799, 'duration': 3.321}, {'text': 'quite scalable the machine learning', 'start': 227.439, 'duration': 4.281}, {'text': 'engineer task will also come right so at', 'start': 229.12, 'duration': 4.64}, {'text': 'the end of the day we are specifically', 'start': 231.72, 'duration': 4.2}, {'text': 'creating an AI product and that product', 'start': 233.76, 'duration': 4.88}, {'text': 'is getting seamlessly integrated with', 'start': 235.92, 'duration': 6.44}, {'text': 'some uh you can probably say web app or', 'start': 238.64, 'duration': 6.0}, {'text': 'Android app or mobile app or Edge', 'start': 242.36, 'duration': 4.68}, {'text': 'devices something as such so I hope you', 'start': 244.64, 'duration': 5.959}, {'text': 'got an idea with respect to AI so it is', 'start': 247.04, 'duration': 5.36}, {'text': 'mostly about building applications that', 'start': 250.599, 'duration': 3.601}, {'text': 'can perform its own tasks without human', 'start': 252.4, 'duration': 3.36}, {'text': \"intervention now let's talk about\", 'start': 254.2, 'duration': 3.719}, {'text': 'machine learning now whenever I talk', 'start': 255.76, 'duration': 4.199}, {'text': 'about machine learning machine learning', 'start': 257.919, 'duration': 5.28}, {'text': 'is a subset of AI so this is basically', 'start': 259.959, 'duration': 5.52}, {'text': 'machine learning it is a subset of AI', 'start': 263.199, 'duration': 4.56}, {'text': 'and the main aim of machine learning is', 'start': 265.479, 'duration': 5.0}, {'text': 'to provide you stats tools', 'start': 267.759, 'duration': 4.0}, {'text': 'to', 'start': 270.479, 'duration': 5.28}, {'text': 'perform to perform various tasks such as', 'start': 271.759, 'duration': 7.761}, {'text': 'statistical analysis statistical', 'start': 275.759, 'duration': 6.241}, {'text': 'analysis', 'start': 279.52, 'duration': 4.44}, {'text': 'visualization', 'start': 282.0, 'duration': 4.44}, {'text': 'visualization', 'start': 283.96, 'duration': 6.16}, {'text': 'prediction and forecasting right so', 'start': 286.44, 'duration': 4.92}, {'text': \"these are some of the examples that I've\", 'start': 290.12, 'duration': 3.84}, {'text': 'have just written it over here but at', 'start': 291.36, 'duration': 4.04}, {'text': 'the end of the day what is machine', 'start': 293.96, 'duration': 3.56}, {'text': 'learning it provides a lot of stats', 'start': 295.4, 'duration': 4.32}, {'text': 'tools to proberbly perform the complete', 'start': 297.52, 'duration': 3.519}, {'text': 'life cycle of a data science project', 'start': 299.72, 'duration': 3.479}, {'text': 'that is specifically required uh in', 'start': 301.039, 'duration': 5.081}, {'text': 'every life cycle from data inje to', 'start': 303.199, 'duration': 4.84}, {'text': 'probably data transformation feature', 'start': 306.12, 'duration': 4.519}, {'text': 'engineering you will be required some of', 'start': 308.039, 'duration': 4.561}, {'text': 'the other concepts with respect to ml', 'start': 310.639, 'duration': 4.601}, {'text': 'techniques where this is a very', 'start': 312.6, 'duration': 4.92}, {'text': 'important term specifically if I say', 'start': 315.24, 'duration': 4.519}, {'text': 'about that is nothing but stats tools', 'start': 317.52, 'duration': 4.36}, {'text': 'okay so machine learning is a subset of', 'start': 319.759, 'duration': 4.601}, {'text': 'AI right and here it is providing the', 'start': 321.88, 'duration': 5.24}, {'text': 'stats tools to perform all this task and', 'start': 324.36, 'duration': 5.36}, {'text': 'this task is usually performed on what', 'start': 327.12, 'duration': 5.799}, {'text': 'on data now why we do this why we do', 'start': 329.72, 'duration': 4.72}, {'text': 'this so', 'start': 332.919, 'duration': 5.521}, {'text': 'that so that we understand about the', 'start': 334.44, 'duration': 8.72}, {'text': 'data we understand about the data right', 'start': 338.44, 'duration': 6.4}, {'text': 'so that a data will be meaningful it', 'start': 343.16, 'duration': 3.52}, {'text': 'will be able to convey some information', 'start': 344.84, 'duration': 4.16}, {'text': 'to you right so that is where machine', 'start': 346.68, 'duration': 4.639}, {'text': 'learning basically comes into existence', 'start': 349.0, 'duration': 4.36}, {'text': 'now coming to the next part that is', 'start': 351.319, 'duration': 5.121}, {'text': 'nothing but deep learning so if I talk', 'start': 353.36, 'duration': 4.64}, {'text': 'about deep learning again deep learning', 'start': 356.44, 'duration': 4.36}, {'text': 'is a subset of machine learning', 'start': 358.0, 'duration': 4.68}, {'text': 'and if I talk about deep learning from', 'start': 360.8, 'duration': 3.72}, {'text': \"1950s it's not like deep learning has\", 'start': 362.68, 'duration': 3.68}, {'text': 'become just famous right now yes it has', 'start': 364.52, 'duration': 4.6}, {'text': 'become famous right now because of', 'start': 366.36, 'duration': 4.76}, {'text': 'amazing things like gpus technological', 'start': 369.12, 'duration': 3.72}, {'text': 'advancement open source libraries and', 'start': 371.12, 'duration': 5.079}, {'text': 'many more things but this this entire', 'start': 372.84, 'duration': 7.079}, {'text': 'deep learning was built to mimic human', 'start': 376.199, 'duration': 8.56}, {'text': 'brain right human brain we wanted we', 'start': 379.919, 'duration': 7.881}, {'text': 'wanted AI or we wanted machines to', 'start': 384.759, 'duration': 4.961}, {'text': 'perform like how we human beings used to', 'start': 387.8, 'duration': 4.399}, {'text': 'perform right how we human being used to', 'start': 389.72, 'duration': 5.4}, {'text': 'learn so that is the reason as I said', 'start': 392.199, 'duration': 5.081}, {'text': 'mimicking human brain and that is where', 'start': 395.12, 'duration': 4.32}, {'text': 'we have something called as', 'start': 397.28, 'duration': 5.359}, {'text': 'multi-layered neural networks right', 'start': 399.44, 'duration': 5.479}, {'text': 'multi-layered neural networks so I hope', 'start': 402.639, 'duration': 5.481}, {'text': 'you got a clear idea about this and here', 'start': 404.919, 'duration': 5.68}, {'text': 'whenever I talk about deep learning', 'start': 408.12, 'duration': 3.919}, {'text': 'there are three important things that we', 'start': 410.599, 'duration': 4.281}, {'text': 'specifically learn right please', 'start': 412.039, 'duration': 4.241}, {'text': 'understand this because after this only', 'start': 414.88, 'duration': 3.039}, {'text': \"we'll be able to understand about\", 'start': 416.28, 'duration': 3.96}, {'text': 'generative AI so with respect to deep', 'start': 417.919, 'duration': 4.0}, {'text': 'learning the three important things that', 'start': 420.24, 'duration': 5.88}, {'text': 'we specifically learn right a Ann right', 'start': 421.919, 'duration': 7.441}, {'text': 'CNN and then we basically say RNN and', 'start': 426.12, 'duration': 6.88}, {'text': 'its variants right and this is where', 'start': 429.36, 'duration': 6.399}, {'text': 'when I say RNN and its variant CNN and', 'start': 433.0, 'duration': 5.52}, {'text': 'object detection CNN object detection is', 'start': 435.759, 'duration': 6.0}, {'text': 'completely for computer vision purpose', 'start': 438.52, 'duration': 6.119}, {'text': 'right so if I talk about task over here', 'start': 441.759, 'duration': 6.0}, {'text': 'specifically you use computer vision', 'start': 444.639, 'duration': 5.601}, {'text': 'over here you specifically use for what', 'start': 447.759, 'duration': 4.601}, {'text': 'kind of use cases for textt related use', 'start': 450.24, 'duration': 5.92}, {'text': 'cases right text related use', 'start': 452.36, 'duration': 7.08}, {'text': 'cases right or you can also use it for', 'start': 456.16, 'duration': 5.36}, {'text': 'time series use', 'start': 459.44, 'duration': 4.719}, {'text': 'cases because that is how RNN and its', 'start': 461.52, 'duration': 5.16}, {'text': 'variants are designed Right Time series', 'start': 464.159, 'duration': 7.401}, {'text': 'use cases so Ann is definitely like how', 'start': 466.68, 'duration': 6.239}, {'text': 'machine learning is basically trained', 'start': 471.56, 'duration': 3.12}, {'text': 'similarly you can train machine learning', 'start': 472.919, 'duration': 3.481}, {'text': 'problem statement with the help of a&n', 'start': 474.68, 'duration': 4.479}, {'text': 'also right so overall most of the things', 'start': 476.4, 'duration': 4.759}, {'text': 'that we specifically learn in deep', 'start': 479.159, 'duration': 3.961}, {'text': 'learning are based on these three things', 'start': 481.159, 'duration': 4.841}, {'text': 'okay when I say CNN object detection', 'start': 483.12, 'duration': 4.56}, {'text': 'there are techniques like rcnn many more', 'start': 486.0, 'duration': 3.96}, {'text': 'things and all right similarly RNN you', 'start': 487.68, 'duration': 5.44}, {'text': 'have RNN LTM RNN Gru then you have', 'start': 489.96, 'duration': 4.959}, {'text': 'encoder decoder attention is all you', 'start': 493.12, 'duration': 4.199}, {'text': 'need then you have Transformers and', 'start': 494.919, 'duration': 4.28}, {'text': 'birds right so I hope everybody has', 'start': 497.319, 'duration': 5.041}, {'text': 'learned from my playlist till here', 'start': 499.199, 'duration': 5.161}, {'text': 'everything has been explained along with', 'start': 502.36, 'duration': 3.399}, {'text': 'theoretical intuition and practical', 'start': 504.36, 'duration': 3.399}, {'text': 'intuition Transformer and B are', 'start': 505.759, 'duration': 4.201}, {'text': 'something very Advanced and and from', 'start': 507.759, 'duration': 4.72}, {'text': 'here only we will be deriving the next', 'start': 509.96, 'duration': 5.439}, {'text': 'thing that is nothing but generative AI', 'start': 512.479, 'duration': 6.841}, {'text': 'okay because this is the backbone used', 'start': 515.399, 'duration': 5.76}, {'text': 'in most of the llm models in generative', 'start': 519.32, 'duration': 4.719}, {'text': 'AI Transformers and birds okay so deep', 'start': 521.159, 'duration': 5.001}, {'text': 'learning is mostly about this specific', 'start': 524.039, 'duration': 3.961}, {'text': 'thing at the end of the day we are', 'start': 526.16, 'duration': 3.359}, {'text': 'trying to mimic the human brain we are', 'start': 528.0, 'duration': 3.24}, {'text': 'trying to understand how human beings', 'start': 529.519, 'duration': 3.161}, {'text': 'specifically learn we also learn in the', 'start': 531.24, 'duration': 3.84}, {'text': 'same way now coming to the next one that', 'start': 532.68, 'duration': 4.48}, {'text': 'is nothing but generative AI obviously', 'start': 535.08, 'duration': 4.72}, {'text': 'generative AI is a subset of deep', 'start': 537.16, 'duration': 3.72}, {'text': 'learning', 'start': 539.8, 'duration': 4.92}, {'text': 'again and here Advanced things okay so I', 'start': 540.88, 'duration': 5.88}, {'text': 'will specifically talk about two types', 'start': 544.72, 'duration': 3.84}, {'text': 'of model that we use in data science', 'start': 546.76, 'duration': 5.16}, {'text': 'Industry models or two types of model', 'start': 548.56, 'duration': 5.279}, {'text': 'training we specifically say right one', 'start': 551.92, 'duration': 5.12}, {'text': 'is the discriminative uh if I if I just', 'start': 553.839, 'duration': 5.041}, {'text': \"want to say it is that it's that's\", 'start': 557.04, 'duration': 3.88}, {'text': 'mostly like discriminative and', 'start': 558.88, 'duration': 4.16}, {'text': 'generative models okay so if I talk', 'start': 560.92, 'duration': 4.12}, {'text': 'about deep learning models they are', 'start': 563.04, 'duration': 4.56}, {'text': 'mostly of two', 'start': 565.04, 'duration': 5.64}, {'text': 'types okay this is one and this is the', 'start': 567.6, 'duration': 4.359}, {'text': 'other one', 'start': 570.68, 'duration': 4.279}, {'text': 'okay here you have something called as', 'start': 571.959, 'duration': 5.761}, {'text': 'discriminative models here you have', 'start': 574.959, 'duration': 5.161}, {'text': 'something called as generative models', 'start': 577.72, 'duration': 4.2}, {'text': 'now you should understand whenever I', 'start': 580.12, 'duration': 4.0}, {'text': 'talk about generative AI you should', 'start': 581.92, 'duration': 4.159}, {'text': 'understand one very important thing', 'start': 584.12, 'duration': 4.32}, {'text': 'generative AI is more about generating', 'start': 586.079, 'duration': 5.841}, {'text': 'content okay so these are specific', 'start': 588.44, 'duration': 6.12}, {'text': 'models which will help you to generate', 'start': 591.92, 'duration': 5.359}, {'text': 'new content okay based on whatever', 'start': 594.56, 'duration': 4.6}, {'text': 'content it has already been trained on', 'start': 597.279, 'duration': 4.56}, {'text': 'okay if I talk about discriminative AI', 'start': 599.16, 'duration': 6.4}, {'text': 'it is mostly about task like', 'start': 601.839, 'duration': 6.801}, {'text': 'classification classification prediction', 'start': 605.56, 'duration': 5.12}, {'text': 'all this regression prediction so all', 'start': 608.64, 'duration': 4.52}, {'text': 'this tasks you can basically do in short', 'start': 610.68, 'duration': 6.399}, {'text': 'over here your data set that you have', 'start': 613.16, 'duration': 7.52}, {'text': 'right these are this entire', 'start': 617.079, 'duration': 5.641}, {'text': 'discriminative models are trained on', 'start': 620.68, 'duration': 4.64}, {'text': 'labeled data set you have to really', 'start': 622.72, 'duration': 6.08}, {'text': 'understand this okay label data set', 'start': 625.32, 'duration': 6.12}, {'text': 'similarly in the case of generative AI', 'start': 628.8, 'duration': 4.52}, {'text': 'if I really want to understand about the', 'start': 631.44, 'duration': 5.44}, {'text': 'task it is nothing but it', 'start': 633.32, 'duration': 6.24}, {'text': 'generates new', 'start': 636.88, 'duration': 6.12}, {'text': 'data trained', 'start': 639.56, 'duration': 3.44}, {'text': 'on huge data set okay if I really want', 'start': 643.48, 'duration': 7.64}, {'text': 'to make you understand right in a simple', 'start': 648.32, 'duration': 7.0}, {'text': 'way if I just take okay I I am a person', 'start': 651.12, 'duration': 7.279}, {'text': \"what I've done is that I have probably\", 'start': 655.32, 'duration': 6.28}, {'text': 'learned or read 100 books on', 'start': 658.399, 'duration': 6.401}, {'text': 'cats right so I have been trained on', 'start': 661.6, 'duration': 5.039}, {'text': 'this many number of books huge amount of', 'start': 664.8, 'duration': 5.52}, {'text': 'data right now what I being a person if', 'start': 666.639, 'duration': 5.401}, {'text': 'anybody ask me any questions with', 'start': 670.32, 'duration': 4.28}, {'text': 'respect to cats I will be able to answer', 'start': 672.04, 'duration': 5.28}, {'text': 'all the questions in my own way right', 'start': 674.6, 'duration': 4.039}, {'text': 'and obviously the answers will be', 'start': 677.32, 'duration': 3.4}, {'text': \"accurate because I've already read 100\", 'start': 678.639, 'duration': 4.401}, {'text': 'books on the cat so similarly if I talk', 'start': 680.72, 'duration': 4.4}, {'text': 'with respect to generative AI there are', 'start': 683.04, 'duration': 3.799}, {'text': 'two types of models that we specifically', 'start': 685.12, 'duration': 3.76}, {'text': 'learn one is large language models large', 'start': 686.839, 'duration': 4.361}, {'text': 'image models large language model is', 'start': 688.88, 'duration': 4.72}, {'text': 'with respect to Text data large image', 'start': 691.2, 'duration': 4.04}, {'text': 'model is specifically with respect to', 'start': 693.6, 'duration': 4.039}, {'text': 'images and videos so here if a text is', 'start': 695.24, 'duration': 3.96}, {'text': 'given you can convert that into an image', 'start': 697.639, 'duration': 3.64}, {'text': 'if a text if a text is given you can', 'start': 699.2, 'duration': 5.6}, {'text': 'convert that into videos here large', 'start': 701.279, 'duration': 5.401}, {'text': 'language mod if a text is given it will', 'start': 704.8, 'duration': 3.52}, {'text': 'be able to provide some response in', 'start': 706.68, 'duration': 4.36}, {'text': 'terms of text right and if I talk about', 'start': 708.32, 'duration': 4.519}, {'text': 'all the various categories of LM models', 'start': 711.04, 'duration': 3.4}, {'text': \"just in some time I'll be explaining you\", 'start': 712.839, 'duration': 4.601}, {'text': 'that also okay so generative AI in short', 'start': 714.44, 'duration': 6.04}, {'text': 'what it is basically doing is that here', 'start': 717.44, 'duration': 5.399}, {'text': 'we have models that is already trained', 'start': 720.48, 'duration': 4.799}, {'text': 'in huge amount of data and the task of', 'start': 722.839, 'duration': 4.961}, {'text': 'that specific models are based on any', 'start': 725.279, 'duration': 4.68}, {'text': 'input it will generate a new data itself', 'start': 727.8, 'duration': 4.719}, {'text': 'okay now to make you understand more', 'start': 729.959, 'duration': 5.281}, {'text': 'about llm models right so if I talk', 'start': 732.519, 'duration': 5.281}, {'text': 'about more llm models right obviously', 'start': 735.24, 'duration': 5.719}, {'text': 'you know companies like open', 'start': 737.8, 'duration': 6.32}, {'text': 'AI you know companies like', 'start': 740.959, 'duration': 5.081}, {'text': 'meta', 'start': 744.12, 'duration': 5.36}, {'text': \"Google anthropic right and every body's\", 'start': 746.04, 'duration': 5.96}, {'text': 'race in in the race right to generate', 'start': 749.48, 'duration': 5.2}, {'text': 'the best llm model so this mod this this', 'start': 752.0, 'duration': 4.0}, {'text': 'companies are already doing really', 'start': 754.68, 'duration': 3.64}, {'text': 'really well anthropic basically comes up', 'start': 756.0, 'duration': 4.839}, {'text': 'with a model which is called as cloudy 3', 'start': 758.32, 'duration': 4.36}, {'text': 'right right now it is being a fierce', 'start': 760.839, 'duration': 5.761}, {'text': 'competitor of open a GPD 4 right gbd4', 'start': 762.68, 'duration': 5.719}, {'text': 'then you have in meta you have open', 'start': 766.6, 'duration': 4.88}, {'text': 'source models like Lama 2 Google I hope', 'start': 768.399, 'duration': 5.641}, {'text': 'everybody has heard about gini right in', 'start': 771.48, 'duration': 4.159}, {'text': 'Google an open source model has also', 'start': 774.04, 'duration': 4.4}, {'text': 'come which is called as Gemma right now', 'start': 775.639, 'duration': 4.801}, {'text': 'what are all all these specific models', 'start': 778.44, 'duration': 4.12}, {'text': 'these models are nothing but these are', 'start': 780.44, 'duration': 5.44}, {'text': 'specifically called as Foundation', 'start': 782.56, 'duration': 6.079}, {'text': 'models okay these Foundation models are', 'start': 785.88, 'duration': 5.84}, {'text': 'also called as pre-trained models why we', 'start': 788.639, 'duration': 5.521}, {'text': 'say it as pre-trained models because', 'start': 791.72, 'duration': 5.16}, {'text': 'these are trained in huge amount of data', 'start': 794.16, 'duration': 6.64}, {'text': 'the entire internet data huge', 'start': 796.88, 'duration': 7.6}, {'text': 'data it has been trained in huge data', 'start': 800.8, 'duration': 6.2}, {'text': 'the entire internet data right it may be', 'start': 804.48, 'duration': 4.359}, {'text': 'code it may be multiple things and all', 'start': 807.0, 'duration': 2.8}, {'text': 'right', 'start': 808.839, 'duration': 3.961}, {'text': 'now we can use the specific model for', 'start': 809.8, 'duration': 6.36}, {'text': 'domain specific use cases also domain', 'start': 812.8, 'duration': 6.039}, {'text': 'specific use cases also and that is', 'start': 816.16, 'duration': 5.039}, {'text': 'where a concept something called as fine', 'start': 818.839, 'duration': 4.68}, {'text': 'tuning is used right and I have already', 'start': 821.199, 'duration': 5.161}, {'text': 'created a playlist about fine tuning', 'start': 823.519, 'duration': 5.801}, {'text': \"also I've explained Concepts like clora\", 'start': 826.36, 'duration': 5.279}, {'text': 'Laura how you can basically do the fine', 'start': 829.32, 'duration': 4.72}, {'text': 'tuning how you can do it with uh open', 'start': 831.639, 'duration': 4.681}, {'text': 'source models and many more things right', 'start': 834.04, 'duration': 4.64}, {'text': 'the fierce competition right now is', 'start': 836.32, 'duration': 4.48}, {'text': 'basically to get the best foundation', 'start': 838.68, 'duration': 6.32}, {'text': 'model right and right now gp4 gp4 turbo', 'start': 840.8, 'duration': 7.12}, {'text': 'soon GPT 5 is also going to come right', 'start': 845.0, 'duration': 5.04}, {'text': 'if I talk about open source model Lama 3', 'start': 847.92, 'duration': 4.839}, {'text': 'is there in the pipeline right cloudy', 'start': 850.04, 'duration': 5.68}, {'text': 'has just recently launched cloudy 3 gini', 'start': 852.759, 'duration': 4.88}, {'text': 'is also coming up with German Pro more', 'start': 855.72, 'duration': 3.84}, {'text': 'variants it is basically coming up so', 'start': 857.639, 'duration': 4.76}, {'text': 'the main race if I probably talk about', 'start': 859.56, 'duration': 4.6}, {'text': 'is to create the best foundation model', 'start': 862.399, 'duration': 4.161}, {'text': 'later on many companies will be you able', 'start': 864.16, 'duration': 4.0}, {'text': 'to use this Foundation model in the form', 'start': 866.56, 'duration': 4.32}, {'text': 'of pre-train models or it will also they', 'start': 868.16, 'duration': 5.119}, {'text': 'will also be able to fine tune with some', 'start': 870.88, 'duration': 5.199}, {'text': 'own custom data set right to solve their', 'start': 873.279, 'duration': 4.081}, {'text': 'use', 'start': 876.079, 'duration': 4.241}, {'text': 'cases so this was the entire idea about', 'start': 877.36, 'duration': 5.96}, {'text': 'generative AI again uh this is the video', 'start': 880.32, 'duration': 5.6}, {'text': 'that I really needed to upload uh early', 'start': 883.32, 'duration': 4.079}, {'text': 'but yes many people were waiting', 'start': 885.92, 'duration': 3.64}, {'text': 'requesting for this specific video so I', 'start': 887.399, 'duration': 3.761}, {'text': 'made you understand this entire thing by', 'start': 889.56, 'duration': 4.04}, {'text': 'writing in front of you so for more', 'start': 891.16, 'duration': 4.32}, {'text': 'details with respect to generative AI', 'start': 893.6, 'duration': 3.72}, {'text': 'Lang chain now if I talk about Lang', 'start': 895.48, 'duration': 3.64}, {'text': 'chain it is a framework right Lang chain', 'start': 897.32, 'duration': 3.24}, {'text': 'is a framework which will be able to', 'start': 899.12, 'duration': 3.719}, {'text': 'work with all the specific models at the', 'start': 900.56, 'duration': 4.36}, {'text': 'end of the day we will be able to', 'start': 902.839, 'duration': 5.881}, {'text': 'generate RG application ra', 'start': 904.92, 'duration': 5.839}, {'text': 'application retrieval argumentation', 'start': 908.72, 'duration': 4.559}, {'text': \"query uh and along with that we'll also\", 'start': 910.759, 'duration': 4.681}, {'text': 'be able to develop some amazing chat', 'start': 913.279, 'duration': 4.8}, {'text': 'Bots that is the main reason right we', 'start': 915.44, 'duration': 4.8}, {'text': 'why llm becoming very famous because of', 'start': 918.079, 'duration': 4.921}, {'text': 'the chances of getting automated right', 'start': 920.24, 'duration': 4.839}, {'text': 'we will be able to automate the entire', 'start': 923.0, 'duration': 4.0}, {'text': 'chatbot response things with respect to', 'start': 925.079, 'duration': 4.921}, {'text': 'it not only that it has a use scope in', 'start': 927.0, 'duration': 4.759}, {'text': 'multiple sectors also with respect to', 'start': 930.0, 'duration': 5.0}, {'text': 'various use cases uh this is with mostly', 'start': 931.759, 'duration': 5.481}, {'text': 'about L models L models with respect to', 'start': 935.0, 'duration': 4.56}, {'text': 'large image models stability uh', 'start': 937.24, 'duration': 3.959}, {'text': 'stability AI is a company which is', 'start': 939.56, 'duration': 3.199}, {'text': 'specifically working in this specific', 'start': 941.199, 'duration': 3.401}, {'text': 'thing right so I hope you like this', 'start': 942.759, 'duration': 4.161}, {'text': 'particular video for more videos related', 'start': 944.6, 'duration': 4.4}, {'text': 'to Lang chain generative AI llm models', 'start': 946.92, 'duration': 4.039}, {'text': 'you can follow my other playlist of Lang', 'start': 949.0, 'duration': 3.68}, {'text': \"chain open Ai and all where you'll be\", 'start': 950.959, 'duration': 3.961}, {'text': 'able to see lot of end to-end projects', 'start': 952.68, 'duration': 3.76}, {'text': 'so I hope you like this particular video', 'start': 954.92, 'duration': 2.52}, {'text': 'I will see you all in the next video', 'start': 956.44, 'duration': 2.319}, {'text': 'have a great day thank you and all take', 'start': 957.44, 'duration': 4.24}, {'text': 'care bye-bye', 'start': 958.759, 'duration': 2.921}]\n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_video_metadata(url):\n",
    "    \"\"\"Fetch video metadata using yt-dlp.\"\"\"\n",
    "    ydl_opts = {\"quiet\": True}\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            info = ydl.extract_info(url, download=False)\n",
    "            title = info.get(\"title\", \"Unknown Title\")\n",
    "            duration = info.get(\"duration\", \"Unknown Duration\")\n",
    "            print(f\"Title: {title}, Duration: {duration} seconds\")\n",
    "            return info\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching metadata: {e}\")\n",
    "            return None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    \"\"\"Fetch video transcript using youtube_transcript_api.\"\"\"\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"Transcript fetch error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Your YouTube video URL\n",
    "url = \"https://www.youtube.com/watch?v=X7Zd4VyUgL0\"\n",
    "\n",
    "# Extract video metadata\n",
    "metadata = get_video_metadata(url)\n",
    "\n",
    "# Extract video ID and fetch transcript\n",
    "if metadata:\n",
    "    video_id = metadata[\"id\"]\n",
    "    transcript = get_transcript(video_id)\n",
    "    print(\"Transcript:\", transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
